{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRhz6yT78vMQRUukzEaC2j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPm4j5ThMnjz","executionInfo":{"status":"ok","timestamp":1759832735060,"user_tz":-660,"elapsed":21818,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"55ee8e02-6110-4309-98ec-274582ad9810"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Train CSV: /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/train/Train_All.csv\n","Test  CSV: /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/test/Test_All.csv\n","Output   : /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest\n"]}],"source":["# Reviewer note: keep mount and path configuration isolated to make the notebook portable\n","\n","import os\n","import sys\n","from pathlib import Path\n","from google.colab import drive\n","\n","# Mount Google Drive if not already mounted\n","if not os.path.ismount(\"/content/drive\"):\n","    drive.mount(\"/content/drive\", force_remount=False)\n","\n","# Folders containing the CSVs\n","TRAIN_DIR = Path(\"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/train\")\n","TEST_DIR  = Path(\"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/test\")\n","\n","# Expected CSV filenames to prevent accidental mix-ups\n","TRAIN_NAME = \"Train_All.csv\"\n","TEST_NAME  = \"Test_All.csv\"\n","\n","TRAIN_CSV = TRAIN_DIR / TRAIN_NAME\n","TEST_CSV  = TEST_DIR / TEST_NAME\n","\n","if not TRAIN_CSV.is_file():\n","    raise FileNotFoundError(f\"Expected training CSV not found: {TRAIN_CSV}\")\n","if not TEST_CSV.is_file():\n","    raise FileNotFoundError(f\"Expected testing CSV not found: {TEST_CSV}\")\n","\n","# Output directory for metrics and artifacts\n","OUT_DIR = Path(\"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest\")\n","\n","# Safety guard: if the folder exists and is non-empty, warn and stop to protect previous work\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new output folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","# If it doesn't exist or is empty, create it\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(\"Train CSV:\", TRAIN_CSV)\n","print(\"Test  CSV:\", TEST_CSV)\n","print(\"Output   :\", OUT_DIR)\n"]},{"cell_type":"code","source":["# Reviewer note: no preprocessing is applied; dataset is assumed to be clean and labeled\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Expected raw feature columns (exact names from the files)\n","FEATURES = [\"resistance_gassensor\", \"pressure\", \"temperature\", \"relative_humidity\"]\n","\n","# Expected label column (numeric in the files)\n","LABEL_COL = \"target\"\n","\n","# Load train and test exactly as-is\n","train_df = pd.read_csv(TRAIN_CSV)\n","test_df  = pd.read_csv(TEST_CSV)\n","\n","# Basic checks to fail fast if the schema is off\n","missing_train = [c for c in FEATURES + [LABEL_COL] if c not in train_df.columns]\n","missing_test  = [c for c in FEATURES + [LABEL_COL] if c not in test_df.columns]\n","if missing_train:\n","    raise ValueError(f\"Train is missing columns: {missing_train}\")\n","if missing_test:\n","    raise ValueError(f\"Test is missing columns: {missing_test}\")\n","\n","# Extract raw numpy arrays for scikit-learn\n","X_train = train_df[FEATURES].values\n","y_train = train_df[LABEL_COL].values\n","X_test  = test_df[FEATURES].values\n","y_test  = test_df[LABEL_COL].values\n","\n","print(\"Train shapes:\", X_train.shape, y_train.shape)\n","print(\"Test shapes :\", X_test.shape, y_test.shape)\n","\n","# Optional sanity prints without altering data\n","print(\"Unique train labels:\", np.unique(y_train))\n","print(\"Unique test  labels:\", np.unique(y_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m933xaPNNIi-","executionInfo":{"status":"ok","timestamp":1759832772130,"user_tz":-660,"elapsed":2572,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"9af05607-debf-466c-acf2-cfed95d4f81e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shapes: (107200, 4) (107200,)\n","Test shapes : (107200, 4) (107200,)\n","Unique train labels: [0 1 2 3]\n","Unique test  labels: [0 1 2 3]\n"]}]},{"cell_type":"code","source":["# Reviewer note: same training/eval flow; now also prints confusion matrix and per-class outcomes to console\n","\n","import time\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","RANDOM_STATE = 42\n","\n","clf = RandomForestClassifier(\n","    n_estimators=300,\n","    max_depth=None,\n","    n_jobs=-1,\n","    random_state=RANDOM_STATE\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions on test set\n","y_pred = clf.predict(X_test)\n","\n","# Core metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report (unchanged)\n","report_csv = OUT_DIR / \"rf_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"rf_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model into the same OUT_DIR, avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"rf_model.joblib\"\n","model_path = model_base\n","if model_base.exists():\n","    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n","    model_path = OUT_DIR / f\"rf_model_{ts}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save scalar metrics and file paths\n","metrics_json = OUT_DIR / \"rf_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"RandomForestClassifier\",\n","            \"n_estimators\": 300,\n","            \"random_state\": RANDOM_STATE,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct / incorrect counts (same logic as before)\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"rf_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output: accuracy, full classification report, labeled confusion matrix, and per-class outcomes\n","print(f\"Random Forest accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7yK7CYyQy3i","executionInfo":{"status":"ok","timestamp":1759833785373,"user_tz":-660,"elapsed":69120,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"bb5c9b71-c069-42d0-b324-ea67cfa895a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest accuracy: 80.66%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.5694    0.9545    0.7133     26800\n","           1     1.0000    1.0000    1.0000     26800\n","           2     0.8566    0.2718    0.4127     26800\n","           3     0.9938    1.0000    0.9969     26800\n","\n","    accuracy                         0.8066    107200\n","   macro avg     0.8549    0.8066    0.7807    107200\n","weighted avg     0.8549    0.8066    0.7807    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              25580                0               1220                0\n","true_Chilli (1)                 0            26800                  0                0\n","true_Cinnamon (2)           19348                0               7285              167\n","true_Nutmeg (3)                 0                0                  0            26800\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         25580            1220                   95.45\n","      1   Chilli       26800         26800               0                  100.00\n","      2 Cinnamon       26800          7285           19515                   27.18\n","      3   Nutmeg       26800         26800               0                  100.00\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest/rf_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest/rf_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest/rf_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest/rf_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/RandomForest/rf_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate Logistic Regression on raw features; adds model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"LogisticRegression\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# Model configuration suitable for multinomial classification without scaling\n","clf = LogisticRegression(\n","    multi_class=\"multinomial\",\n","    solver=\"lbfgs\",\n","    max_iter=2000\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"lr_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"lr_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"lr_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"lr_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"lr_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"LogisticRegression\",\n","            \"multi_class\": \"multinomial\",\n","            \"solver\": \"lbfgs\",\n","            \"max_iter\": 2000,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts, include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"lr_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"Logistic Regression accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IElyYZc6Saub","executionInfo":{"status":"ok","timestamp":1759835147196,"user_tz":-660,"elapsed":94524,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"6bbe3e7b-6103-4cb7-bce8-ddc6aaa43b6c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Logistic Regression accuracy: 45.69%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.3691    0.9519    0.5320     26800\n","           1     0.2886    0.1903    0.2294     26800\n","           2     0.5904    0.0233    0.0448     26800\n","           3     0.9165    0.6619    0.7687     26800\n","\n","    accuracy                         0.4569    107200\n","   macro avg     0.5411    0.4569    0.3937    107200\n","weighted avg     0.5411    0.4569    0.3937    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              25512             1173                 60               55\n","true_Chilli (1)             20329             5100                194             1177\n","true_Cinnamon (2)           23266             2525                624              385\n","true_Nutmeg (3)                 8             8874                179            17739\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         25512            1288                   95.19\n","      1   Chilli       26800          5100           21700                   19.03\n","      2 Cinnamon       26800           624           26176                    2.33\n","      3   Nutmeg       26800         17739            9061                   66.19\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/LogisticRegression/lr_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/LogisticRegression/lr_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/LogisticRegression/lr_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/LogisticRegression/lr_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/LogisticRegression/lr_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate an MLP on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"MLP\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# MLP configured for multiclass; no scaling is applied to honor raw-data requirement\n","clf = MLPClassifier(\n","    hidden_layer_sizes=(256, 128),\n","    activation=\"relu\",\n","    solver=\"adam\",\n","    max_iter=600,\n","    random_state=42,\n","    early_stopping=False\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"mlp_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"mlp_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"mlp_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"mlp_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"mlp_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"MLPClassifier\",\n","            \"hidden_layer_sizes\": [256, 128],\n","            \"activation\": \"relu\",\n","            \"solver\": \"adam\",\n","            \"max_iter\": 600,\n","            \"early_stopping\": False,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts, include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"mlp_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"MLP accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtCvywvkWbcd","executionInfo":{"status":"ok","timestamp":1759835839799,"user_tz":-660,"elapsed":155220,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"a9cec7f3-5abf-4066-9e62-e051da42c413"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP accuracy: 35.28%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.3426    0.8959    0.4957     26800\n","           1     0.0000    0.0000    0.0000     26800\n","           2     0.1899    0.0373    0.0624     26800\n","           3     0.4020    0.4778    0.4366     26800\n","\n","    accuracy                         0.3528    107200\n","   macro avg     0.2336    0.3528    0.2487    107200\n","weighted avg     0.2336    0.3528    0.2487    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              24011                0                841             1948\n","true_Chilli (1)             12216                0               1964            12620\n","true_Cinnamon (2)           21323                0               1000             4477\n","true_Nutmeg (3)             12536                0               1460            12804\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         24011            2789                   89.59\n","      1   Chilli       26800             0           26800                    0.00\n","      2 Cinnamon       26800          1000           25800                    3.73\n","      3   Nutmeg       26800         12804           13996                   47.78\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/MLP/mlp_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/MLP/mlp_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/MLP/mlp_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/MLP/mlp_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/MLP/mlp_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate a linear SVM on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"SVM\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# Linear SVM configuration suitable for large n_samples and small n_features\n","clf = LinearSVC(\n","    C=1.0,\n","    random_state=42,\n","    dual=False,     # preferred when n_samples >> n_features\n","    max_iter=5000\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"svm_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"svm_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"svm_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"svm_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"svm_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"LinearSVC\",\n","            \"C\": 1.0,\n","            \"dual\": False,\n","            \"max_iter\": 5000,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts, include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"svm_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"SVM (LinearSVC) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Qqmqz2fZKOm","executionInfo":{"status":"ok","timestamp":1759836114026,"user_tz":-660,"elapsed":580,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"42fbca8a-3839-4b51-dbcf-eecca2fabe7f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM (LinearSVC) accuracy: 25.92%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.3017    0.2924    0.2970     26800\n","           1     0.0000    0.0000    0.0000     26800\n","           2     0.0619    0.0025    0.0048     26800\n","           3     0.2481    0.7419    0.3718     26800\n","\n","    accuracy                         0.2592    107200\n","   macro avg     0.1529    0.2592    0.1684    107200\n","weighted avg     0.1529    0.2592    0.1684    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)               7837                0                105            18858\n","true_Chilli (1)              4891                0                 70            21839\n","true_Cinnamon (2)            7169                0                 67            19564\n","true_Nutmeg (3)              6077                0                840            19883\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800          7837           18963                   29.24\n","      1   Chilli       26800             0           26800                    0.00\n","      2 Cinnamon       26800            67           26733                    0.25\n","      3   Nutmeg       26800         19883            6917                   74.19\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SVM/svm_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SVM/svm_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SVM/svm_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SVM/svm_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SVM/svm_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate an SGD linear classifier on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"SGD\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# SGD configured for multinomial logistic regression style training\n","clf = SGDClassifier(\n","    loss=\"log_loss\",\n","    penalty=\"l2\",\n","    alpha=1e-4,\n","    max_iter=5000,\n","    tol=1e-4,\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"sgd_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"sgd_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"sgd_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"sgd_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"sgd_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"SGDClassifier\",\n","            \"loss\": \"log_loss\",\n","            \"penalty\": \"l2\",\n","            \"alpha\": 1e-4,\n","            \"max_iter\": 5000,\n","            \"tol\": 1e-4,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts, include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"sgd_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"SGD accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cv-bdSyZaEcJ","executionInfo":{"status":"ok","timestamp":1759836446653,"user_tz":-660,"elapsed":22092,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"0d4d7779-9e05-438b-d3ce-1ced4c2ce0a1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["SGD accuracy: 31.04%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000     26800\n","           1     0.4096    0.3660    0.3866     26800\n","           2     0.2819    0.8757    0.4265     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.3104    107200\n","   macro avg     0.1729    0.3104    0.2033    107200\n","weighted avg     0.1729    0.3104    0.2033    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)                  0             1486              25314                0\n","true_Chilli (1)                 0             9810              16990                0\n","true_Cinnamon (2)               0             3331              23469                0\n","true_Nutmeg (3)                 0             9325              17475                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800             0           26800                    0.00\n","      1   Chilli       26800          9810           16990                   36.60\n","      2 Cinnamon       26800         23469            3331                   87.57\n","      3   Nutmeg       26800             0           26800                    0.00\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SGD/sgd_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SGD/sgd_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SGD/sgd_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SGD/sgd_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/SGD/sgd_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate a gradient boosting classifier on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"GradientBoosting\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# HistGradientBoosting scales to large datasets; early_stopping disabled to avoid internal validation split\n","clf = HistGradientBoostingClassifier(\n","    loss=\"log_loss\",\n","    learning_rate=0.1,\n","    max_iter=200,\n","    max_depth=None,\n","    early_stopping=False,\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"gb_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"gb_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"gb_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"gb_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"gb_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"HistGradientBoostingClassifier\",\n","            \"loss\": \"log_loss\",\n","            \"learning_rate\": 0.1,\n","            \"max_iter\": 200,\n","            \"max_depth\": None,\n","            \"early_stopping\": False,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts; include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"gb_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"Gradient Boosting accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHJOTq9-bzDw","executionInfo":{"status":"ok","timestamp":1759836609972,"user_tz":-660,"elapsed":15869,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"abf75364-5a3f-4a60-99ee-dec60dd2d50b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient Boosting accuracy: 81.09%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.5758    0.9494    0.7168     26800\n","           1     1.0000    1.0000    1.0000     26800\n","           2     0.8532    0.2943    0.4376     26800\n","           3     0.9937    1.0000    0.9969     26800\n","\n","    accuracy                         0.8109    107200\n","   macro avg     0.8557    0.8109    0.7878    107200\n","weighted avg     0.8557    0.8109    0.7878    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              25443                0               1357                0\n","true_Chilli (1)                 0            26800                  0                0\n","true_Cinnamon (2)           18745                0               7886              169\n","true_Nutmeg (3)                 0                0                  0            26800\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         25443            1357                   94.94\n","      1   Chilli       26800         26800               0                  100.00\n","      2 Cinnamon       26800          7886           18914                   29.43\n","      3   Nutmeg       26800         26800               0                  100.00\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/GradientBoosting/gb_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/GradientBoosting/gb_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/GradientBoosting/gb_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/GradientBoosting/gb_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/GradientBoosting/gb_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate AdaBoost on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"AdaBoost\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# AdaBoost with decision-stump base estimator; SAMME for multiclass on current sklearn in Colab\n","clf = AdaBoostClassifier(\n","    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n","    n_estimators=300,\n","    learning_rate=0.5,\n","    algorithm=\"SAMME\",\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"ada_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"ada_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"ada_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"ada_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"ada_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"AdaBoostClassifier\",\n","            \"base_estimator\": \"DecisionTree(max_depth=1)\",\n","            \"n_estimators\": 300,\n","            \"learning_rate\": 0.5,\n","            \"algorithm\": \"SAMME\",\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts; include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"ada_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"AdaBoost accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlMC_GI_ciDd","executionInfo":{"status":"ok","timestamp":1759836826250,"user_tz":-660,"elapsed":38012,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"72c73c0b-bf99-4baf-be69-470fb4e35c72"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["AdaBoost accuracy: 51.98%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.1508    0.1747    0.1618     26800\n","           1     1.0000    0.0718    0.1339     26800\n","           2     0.5022    0.8326    0.6265     26800\n","           3     0.8996    1.0000    0.9471     26800\n","\n","    accuracy                         0.5198    107200\n","   macro avg     0.6381    0.5198    0.4673    107200\n","weighted avg     0.6381    0.5198    0.4673    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)               4681                0              22119                0\n","true_Chilli (1)             24877             1923                  0                0\n","true_Cinnamon (2)            1493                0              22315             2992\n","true_Nutmeg (3)                 0                0                  0            26800\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800          4681           22119                   17.47\n","      1   Chilli       26800          1923           24877                    7.18\n","      2 Cinnamon       26800         22315            4485                   83.26\n","      3   Nutmeg       26800         26800               0                  100.00\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/AdaBoost/ada_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/AdaBoost/ada_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/AdaBoost/ada_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/AdaBoost/ada_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/AdaBoost/ada_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate KNN on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"KNN\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# KNN configuration; kd_tree selected for low-dimensional features to improve query speed\n","clf = KNeighborsClassifier(\n","    n_neighbors=7,\n","    weights=\"distance\",\n","    algorithm=\"kd_tree\",\n","    leaf_size=30,\n","    p=2,\n","    n_jobs=-1\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"knn_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"knn_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"knn_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"knn_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"knn_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"KNeighborsClassifier\",\n","            \"n_neighbors\": 7,\n","            \"weights\": \"distance\",\n","            \"algorithm\": \"kd_tree\",\n","            \"leaf_size\": 30,\n","            \"p\": 2,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts; include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"knn_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"KNN accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9AC1FJacw3x","executionInfo":{"status":"ok","timestamp":1759837000527,"user_tz":-660,"elapsed":2539,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"556bfc2b-af6f-486a-fa80-4f92a66546e8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["KNN accuracy: 74.93%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.6214    0.6372    0.6292     26800\n","           1     0.8864    0.8717    0.8790     26800\n","           2     0.6071    0.6390    0.6227     26800\n","           3     0.9048    0.8495    0.8763     26800\n","\n","    accuracy                         0.7493    107200\n","   macro avg     0.7550    0.7493    0.7518    107200\n","weighted avg     0.7550    0.7493    0.7518    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              17077             1326               7670              727\n","true_Chilli (1)              1398            23361               1303              738\n","true_Cinnamon (2)            7994              752              17125              929\n","true_Nutmeg (3)              1011              915               2108            22766\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         17077            9723                   63.72\n","      1   Chilli       26800         23361            3439                   87.17\n","      2 Cinnamon       26800         17125            9675                   63.90\n","      3   Nutmeg       26800         22766            4034                   84.95\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/KNN/knn_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/KNN/knn_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/KNN/knn_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/KNN/knn_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/KNN/knn_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate a compact 1D CNN on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import os\n","import time\n","import sys\n","import json\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"CNN\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Reproducibility\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# Prepare tensors for CNN; reshape only, no value transformation\n","X_train_cnn = X_train.astype(np.float32).reshape(-1, 4, 1)\n","X_test_cnn  = X_test.astype(np.float32).reshape(-1, 4, 1)\n","num_classes = int(len(np.unique(y_train)))\n","\n","# Build a minimal 1D CNN suitable for very short sequences (length 4)\n","inputs = keras.Input(shape=(4, 1))\n","x = layers.Conv1D(filters=32, kernel_size=2, activation=\"relu\")(inputs)\n","x = layers.Conv1D(filters=32, kernel_size=2, activation=\"relu\")(x)\n","x = layers.GlobalAveragePooling1D()(x)\n","x = layers.Dense(64, activation=\"relu\")(x)\n","outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs, name=\"cnn_tabular_1d\")\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Train without creating any derived validation split to keep datasets untouched\n","start = time.time()\n","history = model.fit(\n","    X_train_cnn, y_train,\n","    epochs=25,\n","    batch_size=1024,\n","    verbose=1\n",")\n","train_time = time.time() - start\n","\n","# Predictions and metrics\n","y_pred_proba = model.predict(X_test_cnn, batch_size=4096, verbose=0)\n","y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"cnn_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"cnn_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model as .keras; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"cnn_model.keras\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"cnn_model_{time.strftime('%Y%m%d_%H%M%S')}.keras\"\n","model.save(model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"cnn_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"Keras 1D CNN\",\n","            \"input_shape\": [4, 1],\n","            \"epochs\": 25,\n","            \"batch_size\": 1024,\n","            \"optimizer\": \"adam\",\n","            \"loss\": \"sparse_categorical_crossentropy\",\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts; include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"cnn_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"CNN accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMrEBND0dbed","executionInfo":{"status":"ok","timestamp":1759837230204,"user_tz":-660,"elapsed":52220,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"5109f9c2-44d1-4b4f-a457-629512d4ecd0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.2514 - loss: 8742.8770\n","Epoch 2/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2728 - loss: 457.9503\n","Epoch 3/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2590 - loss: 607.4549\n","Epoch 4/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2729 - loss: 468.5874\n","Epoch 5/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.2685 - loss: 429.0386\n","Epoch 6/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2646 - loss: 439.6523\n","Epoch 7/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 358.6685\n","Epoch 8/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2690 - loss: 373.9905\n","Epoch 9/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2689 - loss: 450.1976\n","Epoch 10/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2598 - loss: 451.8861\n","Epoch 11/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2696 - loss: 249.9659\n","Epoch 12/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2622 - loss: 465.6758\n","Epoch 13/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2660 - loss: 358.2359\n","Epoch 14/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2676 - loss: 292.9975\n","Epoch 15/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 283.8656\n","Epoch 16/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2715 - loss: 180.3109\n","Epoch 17/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2633 - loss: 277.1667\n","Epoch 18/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2685 - loss: 232.2311\n","Epoch 19/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2720 - loss: 138.1135\n","Epoch 20/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2727 - loss: 213.9302\n","Epoch 21/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2690 - loss: 202.4817\n","Epoch 22/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2666 - loss: 208.3470\n","Epoch 23/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2773 - loss: 159.9106\n","Epoch 24/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2778 - loss: 169.9766\n","Epoch 25/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2854 - loss: 116.2517\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["CNN accuracy: 25.25%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.2562    0.3100    0.2806     26800\n","           1     0.0000    0.0000    0.0000     26800\n","           2     0.2509    0.7000    0.3694     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.2525    107200\n","   macro avg     0.1268    0.2525    0.1625    107200\n","weighted avg     0.1268    0.2525    0.1625    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)               8309                0              18491                0\n","true_Chilli (1)              8040                0              18760                0\n","true_Cinnamon (2)            8040                0              18760                0\n","true_Nutmeg (3)              8040                0              18760                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800          8309           18491                    31.0\n","      1   Chilli       26800             0           26800                     0.0\n","      2 Cinnamon       26800         18760            8040                    70.0\n","      3   Nutmeg       26800             0           26800                     0.0\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/CNN/cnn_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/CNN/cnn_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/CNN/cnn_model.keras\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/CNN/cnn_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/CNN/cnn_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: train and evaluate XGBoost on raw features; add model persistence and labeled confusion-matrix CSV; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from xgboost import XGBClassifier\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"XGBoost\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Label column fallback for safety\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","num_classes = int(np.unique(y_train).size)\n","\n","# XGBoost configuration suitable for multiclass classification on CPU\n","clf = XGBClassifier(\n","    objective=\"multi:softmax\",\n","    num_class=num_classes,\n","    n_estimators=400,\n","    max_depth=6,\n","    learning_rate=0.1,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    reg_lambda=1.0,\n","    tree_method=\"hist\",\n","    eval_metric=\"mlogloss\",\n","    random_state=42,\n","    n_jobs=-1,\n","    verbosity=0\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predictions and core metrics\n","y_pred = clf.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"test_df\" in globals() and isinstance(test_df, pd.DataFrame) and \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Derive ordered class labels for headings (sorted by numeric target)\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Persist classification report\n","report_csv = OUT_DIR / \"xgb_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Persist confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"xgb_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"xgb_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"xgb_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Persist scalar metrics and file paths\n","metrics_json = OUT_DIR / \"xgb_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"XGBClassifier\",\n","            \"objective\": \"multi:softmax\",\n","            \"num_class\": num_classes,\n","            \"n_estimators\": 400,\n","            \"max_depth\": 6,\n","            \"learning_rate\": 0.1,\n","            \"subsample\": 0.8,\n","            \"colsample_bytree\": 0.8,\n","            \"reg_lambda\": 1.0,\n","            \"tree_method\": \"hist\",\n","            \"eval_metric\": \"mlogloss\",\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Build per-class correct and incorrect counts; include spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"xgb_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output with clear summary\n","print(f\"XGBoost accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sXsVTK_eSwf","executionInfo":{"status":"ok","timestamp":1759837416475,"user_tz":-660,"elapsed":19872,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"7a155a69-daa6-4e5e-ef0c-09f80f9f9ba3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost accuracy: 81.06%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.5809    0.9466    0.7199     26800\n","           1     1.0000    1.0000    1.0000     26800\n","           2     0.8470    0.2960    0.4387     26800\n","           3     0.9795    0.9999    0.9896     26800\n","\n","    accuracy                         0.8106    107200\n","   macro avg     0.8518    0.8106    0.7871    107200\n","weighted avg     0.8518    0.8106    0.7871    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              25369                0               1431                0\n","true_Chilli (1)                 0            26800                  0                0\n","true_Cinnamon (2)           18306                0               7933              561\n","true_Nutmeg (3)                 0                0                  2            26798\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         25369            1431                   94.66\n","      1   Chilli       26800         26800               0                  100.00\n","      2 Cinnamon       26800          7933           18867                   29.60\n","      3   Nutmeg       26800         26798               2                   99.99\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/XGBoost/xgb_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/XGBoost/xgb_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/XGBoost/xgb_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/XGBoost/xgb_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/all_feature/outputs/XGBoost/xgb_per_class_outcomes.csv\n"]}]}]}