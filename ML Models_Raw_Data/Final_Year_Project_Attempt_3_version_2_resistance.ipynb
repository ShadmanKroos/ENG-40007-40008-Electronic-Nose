{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQxVOsClqRxkuOj+tYXdZ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Po1aDSNicG4","executionInfo":{"status":"ok","timestamp":1759838431880,"user_tz":-660,"elapsed":20184,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"9260873f-f39e-41a2-96e2-bcdfff9ed5af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Train CSV: /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/train/Train_All_Specimens_Resistance.csv\n","Test  CSV: /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/test/Test_All_Specimens_Resistance.csv\n","Base out : /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\n"]}],"source":["# Reviewer note: Colab Drive mount and path configuration for resistance feature\n","\n","import os\n","import sys\n","from pathlib import Path\n","from google.colab import drive\n","\n","# Mount Google Drive if not already mounted\n","if not os.path.ismount(\"/content/drive\"):\n","    drive.mount(\"/content/drive\", force_remount=False)\n","\n","# Folders containing the CSVs for resistance feature\n","TRAIN_DIR = Path(\"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/train\")\n","TEST_DIR  = Path(\"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/test\")\n","\n","# Base output directory for all resistance models; model cells will create their own subfolders\n","BASE_OUT = Path(\"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\")\n","BASE_OUT.mkdir(parents=True, exist_ok=True)\n","\n","# Helper to resolve a single CSV inside a directory\n","def resolve_single_csv(dir_path: Path) -> Path:\n","    candidates = list(dir_path.glob(\"*.csv\"))\n","    if len(candidates) == 0:\n","        raise FileNotFoundError(f\"No CSV found in {dir_path}. Put exactly one CSV file in that folder.\")\n","    if len(candidates) > 1:\n","        names = [c.name for c in candidates]\n","        raise FileExistsError(f\"Multiple CSV files found in {dir_path}: {names}. Keep exactly one or specify the exact file.\")\n","    return candidates[0]\n","\n","TRAIN_CSV = resolve_single_csv(TRAIN_DIR)\n","TEST_CSV  = resolve_single_csv(TEST_DIR)\n","\n","print(\"Train CSV:\", TRAIN_CSV)\n","print(\"Test  CSV:\", TEST_CSV)\n","print(\"Base out :\", BASE_OUT)\n"]},{"cell_type":"code","source":["# Reviewer note: dataset loading for single feature 'resistance_gassensor'; no preprocessing or scaling\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Single raw feature column and label column\n","FEATURES = [\"resistance_gassensor\"]\n","LABEL_COL = \"target\"\n","\n","# Load train and test exactly as-is\n","train_df = pd.read_csv(TRAIN_CSV)\n","test_df  = pd.read_csv(TEST_CSV)\n","\n","# Basic checks to fail fast if the schema is off\n","missing_train = [c for c in FEATURES + [LABEL_COL] if c not in train_df.columns]\n","missing_test  = [c for c in FEATURES + [LABEL_COL] if c not in test_df.columns]\n","if missing_train:\n","    raise ValueError(f\"Train is missing columns: {missing_train}\")\n","if missing_test:\n","    raise ValueError(f\"Test is missing columns: {missing_test}\")\n","\n","# Extract raw numpy arrays for scikit-learn\n","X_train = train_df[FEATURES].values\n","y_train = train_df[LABEL_COL].values\n","X_test  = test_df[FEATURES].values\n","y_test  = test_df[LABEL_COL].values\n","\n","print(\"Train shapes:\", X_train.shape, y_train.shape)\n","print(\"Test shapes :\", X_test.shape, y_test.shape)\n","print(\"Unique train labels:\", np.unique(y_train))\n","print(\"Unique test  labels:\", np.unique(y_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4Bq9yh_i38X","executionInfo":{"status":"ok","timestamp":1759838461877,"user_tz":-660,"elapsed":1758,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"971f22c9-825f-43f7-8773-15edac6ecd7d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shapes: (107200, 1) (107200,)\n","Test shapes : (107200, 1) (107200,)\n","Unique train labels: [0 1 2 3]\n","Unique test  labels: [0 1 2 3]\n"]}]},{"cell_type":"code","source":["# Reviewer note: Random Forest on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"RandomForest\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","clf = RandomForestClassifier(\n","    n_estimators=300,\n","    max_depth=None,\n","    n_jobs=-1,\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Build labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"rf_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"rf_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"rf_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"rf_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"rf_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"RandomForestClassifier\",\n","            \"n_estimators\": 300,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"rf_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"Random Forest (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJOzuIs8i-mO","executionInfo":{"status":"ok","timestamp":1759838753921,"user_tz":-660,"elapsed":47718,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"cf37289c-135e-4f1e-9987-893d890f974e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest (resistance) accuracy: 39.89%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.4841    0.4997    0.4918     26800\n","           1     0.4006    0.4039    0.4022     26800\n","           2     0.3572    0.3426    0.3498     26800\n","           3     0.3494    0.3494    0.3494     26800\n","\n","    accuracy                         0.3989    107200\n","   macro avg     0.3978    0.3989    0.3983    107200\n","weighted avg     0.3978    0.3989    0.3983    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              13392             3113               7100             3195\n","true_Chilli (1)              2494            10825               4046             9435\n","true_Cinnamon (2)            8899             3908               9182             4811\n","true_Nutmeg (3)              2881             9177               5377             9365\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         13392           13408                   49.97\n","      1   Chilli       26800         10825           15975                   40.39\n","      2 Cinnamon       26800          9182           17618                   34.26\n","      3   Nutmeg       26800          9365           17435                   34.94\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/RandomForest/rf_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/RandomForest/rf_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/RandomForest/rf_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/RandomForest/rf_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/RandomForest/rf_resistance_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: Logistic Regression on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"LogisticRegression\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# Multinomial logistic regression suitable for 4 classes\n","clf = LogisticRegression(\n","    multi_class=\"multinomial\",\n","    solver=\"lbfgs\",\n","    max_iter=2000\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"lr_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"lr_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"lr_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"lr_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"lr_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"LogisticRegression\",\n","            \"multi_class\": \"multinomial\",\n","            \"solver\": \"lbfgs\",\n","            \"max_iter\": 2000,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"lr_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"Logistic Regression (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqs9iBzmkIo-","executionInfo":{"status":"ok","timestamp":1759838915811,"user_tz":-660,"elapsed":511,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"d85cb59b-764f-45a1-ae8d-077de5a8de26"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Logistic Regression (resistance) accuracy: 25.0%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.2500    1.0000    0.4000     26800\n","           1     0.0000    0.0000    0.0000     26800\n","           2     0.0000    0.0000    0.0000     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.2500    107200\n","   macro avg     0.0625    0.2500    0.1000    107200\n","weighted avg     0.0625    0.2500    0.1000    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              26800                0                  0                0\n","true_Chilli (1)             26800                0                  0                0\n","true_Cinnamon (2)           26800                0                  0                0\n","true_Nutmeg (3)             26800                0                  0                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         26800               0                   100.0\n","      1   Chilli       26800             0           26800                     0.0\n","      2 Cinnamon       26800             0           26800                     0.0\n","      3   Nutmeg       26800             0           26800                     0.0\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/LogisticRegression/lr_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/LogisticRegression/lr_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/LogisticRegression/lr_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/LogisticRegression/lr_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/LogisticRegression/lr_resistance_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: MLP on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"MLP\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# MLP configured for multiclass on a single numeric feature\n","clf = MLPClassifier(\n","    hidden_layer_sizes=(128,),\n","    activation=\"relu\",\n","    solver=\"adam\",\n","    max_iter=600,\n","    random_state=42,\n","    early_stopping=False\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"mlp_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"mlp_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"mlp_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"mlp_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"mlp_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"MLPClassifier\",\n","            \"hidden_layer_sizes\": [128],\n","            \"activation\": \"relu\",\n","            \"solver\": \"adam\",\n","            \"max_iter\": 600,\n","            \"early_stopping\": False,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"mlp_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"MLP (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpfHg9PAkuZ7","executionInfo":{"status":"ok","timestamp":1759839218104,"user_tz":-660,"elapsed":147566,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"9f86eb9e-9b94-4c81-e5ae-e98fd5eb9ed2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP (resistance) accuracy: 25.0%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000     26800\n","           1     0.2500    1.0000    0.4000     26800\n","           2     0.0000    0.0000    0.0000     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.2500    107200\n","   macro avg     0.0625    0.2500    0.1000    107200\n","weighted avg     0.0625    0.2500    0.1000    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)                  0            26800                  0                0\n","true_Chilli (1)                 0            26800                  0                0\n","true_Cinnamon (2)               0            26800                  0                0\n","true_Nutmeg (3)                 0            26800                  0                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800             0           26800                     0.0\n","      1   Chilli       26800         26800               0                   100.0\n","      2 Cinnamon       26800             0           26800                     0.0\n","      3   Nutmeg       26800             0           26800                     0.0\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/MLP/mlp_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/MLP/mlp_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/MLP/mlp_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/MLP/mlp_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/MLP/mlp_resistance_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: linear SVM for single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"SVM\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# Linear SVM configuration suitable for large sample count and small feature count\n","clf = LinearSVC(\n","    C=1.0,\n","    dual=False,\n","    max_iter=5000,\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"svm_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"svm_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"svm_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"svm_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"svm_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"LinearSVC\",\n","            \"C\": 1.0,\n","            \"dual\": False,\n","            \"max_iter\": 5000,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"svm_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"SVM (LinearSVC, resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vSbxrTYl34C","executionInfo":{"status":"ok","timestamp":1759839404877,"user_tz":-660,"elapsed":312,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"1694bb10-e20c-44ca-aade-a7619a838175"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM (LinearSVC, resistance) accuracy: 25.0%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.2500    1.0000    0.4000     26800\n","           1     0.0000    0.0000    0.0000     26800\n","           2     0.0000    0.0000    0.0000     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.2500    107200\n","   macro avg     0.0625    0.2500    0.1000    107200\n","weighted avg     0.0625    0.2500    0.1000    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              26800                0                  0                0\n","true_Chilli (1)             26800                0                  0                0\n","true_Cinnamon (2)           26800                0                  0                0\n","true_Nutmeg (3)             26800                0                  0                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         26800               0                   100.0\n","      1   Chilli       26800             0           26800                     0.0\n","      2 Cinnamon       26800             0           26800                     0.0\n","      3   Nutmeg       26800             0           26800                     0.0\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SVM/svm_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SVM/svm_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SVM/svm_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SVM/svm_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SVM/svm_resistance_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: SGD linear classifier on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"SGD\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# SGD configured for multinomial logistic loss on a single numeric feature\n","clf = SGDClassifier(\n","    loss=\"log_loss\",\n","    penalty=\"l2\",\n","    alpha=1e-4,\n","    max_iter=5000,\n","    tol=1e-4,\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"sgd_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"sgd_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"sgd_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"sgd_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"sgd_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"SGDClassifier\",\n","            \"loss\": \"log_loss\",\n","            \"penalty\": \"l2\",\n","            \"alpha\": 1e-4,\n","            \"max_iter\": 5000,\n","            \"tol\": 1e-4,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"sgd_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"SGD (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tewpt8LSnI_a","executionInfo":{"status":"ok","timestamp":1759839587779,"user_tz":-660,"elapsed":20087,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"5f03db6e-afb1-49b4-d3a5-1073482e3847"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["SGD (resistance) accuracy: 25.0%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.2500    1.0000    0.4000     26800\n","           1     0.0000    0.0000    0.0000     26800\n","           2     0.0000    0.0000    0.0000     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.2500    107200\n","   macro avg     0.0625    0.2500    0.1000    107200\n","weighted avg     0.0625    0.2500    0.1000    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              26800                0                  0                0\n","true_Chilli (1)             26800                0                  0                0\n","true_Cinnamon (2)           26800                0                  0                0\n","true_Nutmeg (3)             26800                0                  0                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         26800               0                   100.0\n","      1   Chilli       26800             0           26800                     0.0\n","      2 Cinnamon       26800             0           26800                     0.0\n","      3   Nutmeg       26800             0           26800                     0.0\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SGD/sgd_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SGD/sgd_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SGD/sgd_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SGD/sgd_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/SGD/sgd_resistance_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: HistGradientBoosting classifier on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"GradientBoosting\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# HistGradientBoosting scales to large datasets; early_stopping disabled to avoid internal validation split\n","clf = HistGradientBoostingClassifier(\n","    loss=\"log_loss\",\n","    learning_rate=0.1,\n","    max_iter=200,\n","    max_depth=None,\n","    early_stopping=False,\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"gb_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"gb_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"gb_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"gb_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"gb_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"HistGradientBoostingClassifier\",\n","            \"loss\": \"log_loss\",\n","            \"learning_rate\": 0.1,\n","            \"max_iter\": 200,\n","            \"max_depth\": None,\n","            \"early_stopping\": False,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"gb_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"Gradient Boosting (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuEceG3zn2Gj","executionInfo":{"status":"ok","timestamp":1759839782288,"user_tz":-660,"elapsed":26287,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"d240ab5e-f0bb-4766-b936-23718e1994fa"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient Boosting (resistance) accuracy: 41.93%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.5371    0.4829    0.5086     26800\n","           1     0.4233    0.4560    0.4390     26800\n","           2     0.3785    0.3785    0.3785     26800\n","           3     0.3515    0.3597    0.3556     26800\n","\n","    accuracy                         0.4193    107200\n","   macro avg     0.4226    0.4193    0.4204    107200\n","weighted avg     0.4226    0.4193    0.4204    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              12943             2734               7592             3531\n","true_Chilli (1)              1628            12222               3613             9337\n","true_Cinnamon (2)            7934             3806              10145             4915\n","true_Nutmeg (3)              1595            10114               5451             9640\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         12943           13857                   48.29\n","      1   Chilli       26800         12222           14578                   45.60\n","      2 Cinnamon       26800         10145           16655                   37.85\n","      3   Nutmeg       26800          9640           17160                   35.97\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/GradientBoosting/gb_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/GradientBoosting/gb_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/GradientBoosting/gb_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/GradientBoosting/gb_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/GradientBoosting/gb_resistance_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: AdaBoost on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"AdaBoost\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# AdaBoost with decision stump base estimator; SAMME for multiclass on current sklearn in Colab\n","clf = AdaBoostClassifier(\n","    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),\n","    n_estimators=300,\n","    learning_rate=0.5,\n","    algorithm=\"SAMME\",\n","    random_state=42\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"ada_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"ada_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"ada_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"ada_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"ada_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"AdaBoostClassifier\",\n","            \"base_estimator\": \"DecisionTree(max_depth=1)\",\n","            \"n_estimators\": 300,\n","            \"learning_rate\": 0.5,\n","            \"algorithm\": \"SAMME\",\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"ada_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"AdaBoost (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iACKzMS4oBrY","executionInfo":{"status":"ok","timestamp":1759839963366,"user_tz":-660,"elapsed":13515,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"30920e94-33c2-4b24-8391-9f4ababb8ecb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["AdaBoost (resistance) accuracy: 36.92%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.4959    0.6204    0.5512     26800\n","           1     0.4157    0.4238    0.4197     26800\n","           2     0.2268    0.2889    0.2541     26800\n","           3     0.3154    0.1438    0.1975     26800\n","\n","    accuracy                         0.3692    107200\n","   macro avg     0.3634    0.3692    0.3556    107200\n","weighted avg     0.3634    0.3692    0.3556    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              16627             1690               6795             1688\n","true_Chilli (1)              1790            11357               9213             4440\n","true_Cinnamon (2)           12940             3883               7742             2235\n","true_Nutmeg (3)              2172            10393              10382             3853\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         16627           10173                   62.04\n","      1   Chilli       26800         11357           15443                   42.38\n","      2 Cinnamon       26800          7742           19058                   28.89\n","      3   Nutmeg       26800          3853           22947                   14.38\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/AdaBoost/ada_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/AdaBoost/ada_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/AdaBoost/ada_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/AdaBoost/ada_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/AdaBoost/ada_resistance_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: KNN on single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"KNN\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# KNN configuration suitable for low-dimensional numeric input\n","clf = KNeighborsClassifier(\n","    n_neighbors=7,\n","    weights=\"distance\",\n","    algorithm=\"kd_tree\",\n","    leaf_size=30,\n","    p=2,\n","    n_jobs=-1\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"knn_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"knn_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"knn_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"knn_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"knn_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"KNeighborsClassifier\",\n","            \"n_neighbors\": 7,\n","            \"weights\": \"distance\",\n","            \"algorithm\": \"kd_tree\",\n","            \"leaf_size\": 30,\n","            \"p\": 2,\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"knn_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"KNN (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOOGd_TYot-g","executionInfo":{"status":"ok","timestamp":1759840135195,"user_tz":-660,"elapsed":1406,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"9cebb503-f32f-403d-b1dc-ecf191c16b2a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["KNN (resistance) accuracy: 33.45%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.3036    0.7812    0.4372     26800\n","           1     0.4101    0.3794    0.3942     26800\n","           2     0.3475    0.1056    0.1620     26800\n","           3     0.3626    0.0716    0.1196     26800\n","\n","    accuracy                         0.3345    107200\n","   macro avg     0.3559    0.3345    0.2782    107200\n","weighted avg     0.3559    0.3345    0.2782    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              20936             2674               2409              781\n","true_Chilli (1)             13899            10169               1195             1537\n","true_Cinnamon (2)           19240             3674               2830             1056\n","true_Nutmeg (3)             14892             8279               1710             1919\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         20936            5864                   78.12\n","      1   Chilli       26800         10169           16631                   37.94\n","      2 Cinnamon       26800          2830           23970                   10.56\n","      3   Nutmeg       26800          1919           24881                    7.16\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/KNN/knn_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/KNN/knn_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/KNN/knn_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/KNN/knn_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/KNN/knn_resistance_per_class_outcomes.csv\n"]}]},{"cell_type":"code","source":["# Reviewer note: 1D CNN on a single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import os\n","import sys\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"CNN\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","# Prepare tensors for CNN; reshape only, no scaling or normalization\n","X_train_cnn = X_train.astype(np.float32).reshape(-1, 1, 1)\n","X_test_cnn  = X_test.astype(np.float32).reshape(-1, 1, 1)\n","num_classes = int(len(np.unique(y_train)))\n","\n","# Minimal 1D CNN for a length-1 sequence; kernel_size=1 acts as a learned linear transform\n","inputs = keras.Input(shape=(1, 1))\n","x = layers.Conv1D(filters=16, kernel_size=1, activation=\"relu\")(inputs)\n","x = layers.Conv1D(filters=16, kernel_size=1, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(32, activation=\"relu\")(x)\n","outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs, name=\"cnn_resistance_1d\")\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Train without validation split to keep datasets unchanged\n","start = time.time()\n","history = model.fit(\n","    X_train_cnn, y_train,\n","    epochs=25,\n","    batch_size=1024,\n","    verbose=1\n",")\n","train_time = time.time() - start\n","\n","# Predictions and metrics\n","y_pred_proba = model.predict(X_test_cnn, batch_size=4096, verbose=0)\n","y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"cnn_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"cnn_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model as .keras; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"cnn_resistance_model.keras\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"cnn_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.keras\"\n","model.save(model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"cnn_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"Keras 1D CNN\",\n","            \"input_shape\": [1, 1],\n","            \"epochs\": 25,\n","            \"batch_size\": 1024,\n","            \"optimizer\": \"adam\",\n","            \"loss\": \"sparse_categorical_crossentropy\",\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"cnn_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"CNN (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RW3V9W67pXss","executionInfo":{"status":"ok","timestamp":1759840356715,"user_tz":-660,"elapsed":24022,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"ce991195-1905-4fd5-a519-941925b7721b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2491 - loss: 47655.1602\n","Epoch 2/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2518 - loss: 1370.4247\n","Epoch 3/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2499 - loss: 1846.0724\n","Epoch 4/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2477 - loss: 1637.3838\n","Epoch 5/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2493 - loss: 1642.0951\n","Epoch 6/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2503 - loss: 1316.3752\n","Epoch 7/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2457 - loss: 1297.3737\n","Epoch 8/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2489 - loss: 1156.9955\n","Epoch 9/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2504 - loss: 1185.6997\n","Epoch 10/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2498 - loss: 804.5749\n","Epoch 11/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2509 - loss: 1305.8849\n","Epoch 12/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2495 - loss: 1445.2603\n","Epoch 13/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2486 - loss: 1057.4653\n","Epoch 14/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2542 - loss: 1043.1271\n","Epoch 15/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2524 - loss: 1297.3707\n","Epoch 16/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2496 - loss: 976.2871\n","Epoch 17/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2526 - loss: 1342.1169\n","Epoch 18/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2517 - loss: 1221.7239\n","Epoch 19/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2521 - loss: 1235.7692\n","Epoch 20/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2558 - loss: 1541.6831\n","Epoch 21/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2486 - loss: 1000.1154\n","Epoch 22/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2533 - loss: 867.5649\n","Epoch 23/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2534 - loss: 1361.3280\n","Epoch 24/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2498 - loss: 801.6398\n","Epoch 25/25\n","\u001b[1m105/105\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2528 - loss: 1030.5811\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["CNN (resistance) accuracy: 25.0%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000     26800\n","           1     0.2500    1.0000    0.4000     26800\n","           2     0.0000    0.0000    0.0000     26800\n","           3     0.0000    0.0000    0.0000     26800\n","\n","    accuracy                         0.2500    107200\n","   macro avg     0.0625    0.2500    0.1000    107200\n","weighted avg     0.0625    0.2500    0.1000    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)                  0            26800                  0                0\n","true_Chilli (1)                 0            26800                  0                0\n","true_Cinnamon (2)               0            26800                  0                0\n","true_Nutmeg (3)                 0            26800                  0                0\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800             0           26800                     0.0\n","      1   Chilli       26800         26800               0                   100.0\n","      2 Cinnamon       26800             0           26800                     0.0\n","      3   Nutmeg       26800             0           26800                     0.0\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/CNN/cnn_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/CNN/cnn_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/CNN/cnn_resistance_model.keras\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/CNN/cnn_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/CNN/cnn_resistance_per_class_outcomes.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: XGBoost on a single raw feature; add model persistence, labeled confusion-matrix CSV, and console prints; no change to core behavior\n","\n","import time\n","import sys\n","import json\n","import joblib\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from xgboost import XGBClassifier\n","\n","# Normalize BASE_OUT with a default and derive OUT_DIR for this model\n","BASE_OUT = Path(globals().get(\n","    \"BASE_OUT\",\n","    \"/content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs\"\n","))\n","OUT_DIR = BASE_OUT / \"XGBoost\"\n","\n","# Safety guard: stop if an existing folder is not empty to protect prior runs\n","if OUT_DIR.exists() and any(OUT_DIR.iterdir()):\n","    print(f\"Safety guard: output folder already exists and is not empty: {OUT_DIR}\")\n","    print(\"Create a new folder or archive/clear the existing one before proceeding.\")\n","    sys.exit(1)\n","\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Safety fallback for label column\n","LABEL_COL = LABEL_COL if \"LABEL_COL\" in globals() else \"target\"\n","\n","num_classes = int(np.unique(y_train).size)\n","\n","# Configuration for multiclass classification on CPU\n","clf = XGBClassifier(\n","    objective=\"multi:softmax\",\n","    num_class=num_classes,\n","    n_estimators=400,\n","    max_depth=6,\n","    learning_rate=0.1,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    reg_lambda=1.0,\n","    tree_method=\"hist\",\n","    eval_metric=\"mlogloss\",\n","    random_state=42,\n","    n_jobs=-1,\n","    verbosity=0\n",")\n","\n","start = time.time()\n","clf.fit(X_train, y_train)\n","train_time = time.time() - start\n","\n","# Predict on test set\n","y_pred = clf.predict(X_test)\n","\n","# Metrics\n","acc = accuracy_score(y_test, y_pred)\n","acc_percent = round(100.0 * acc, 2)\n","report_dict = classification_report(y_test, y_pred, digits=4, output_dict=True)\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Optional spice mapping if present; falls back to blank if column absent\n","spice_map = {}\n","if \"spice\" in test_df.columns:\n","    spice_map = test_df.groupby(LABEL_COL)[\"spice\"].agg(lambda s: s.mode().iat[0]).to_dict()\n","\n","# Labeled headers for confusion matrix\n","unique_classes = np.sort(np.unique(y_test))\n","label_names = []\n","for c in unique_classes:\n","    if spice_map:\n","        label_names.append(f\"{spice_map.get(int(c), '')} ({int(c)})\".strip())\n","    else:\n","        label_names.append(str(int(c)))\n","\n","# Save classification report\n","report_csv = OUT_DIR / \"xgb_resistance_classification_report.csv\"\n","pd.DataFrame(report_dict).transpose().to_csv(report_csv, index=True)\n","\n","# Save confusion matrix with clear headers\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{n}\" for n in label_names],\n","    columns=[f\"pred_{n}\" for n in label_names]\n",")\n","cm_df.index.name = \"true_label\"\n","cm_df.columns.name = \"pred_label\"\n","cm_csv = OUT_DIR / \"xgb_resistance_confusion_matrix.csv\"\n","cm_df.to_csv(cm_csv, index=True)\n","\n","# Persist the trained model; avoid overwriting by timestamping if needed\n","model_base = OUT_DIR / \"xgb_resistance_model.joblib\"\n","model_path = model_base if not model_base.exists() else OUT_DIR / f\"xgb_resistance_model_{time.strftime('%Y%m%d_%H%M%S')}.joblib\"\n","joblib.dump(clf, model_path)\n","\n","# Save metrics summary\n","metrics_json = OUT_DIR / \"xgb_resistance_metrics.json\"\n","with metrics_json.open(\"w\") as f:\n","    json.dump(\n","        {\n","            \"model\": \"XGBClassifier\",\n","            \"objective\": \"multi:softmax\",\n","            \"num_class\": num_classes,\n","            \"n_estimators\": 400,\n","            \"max_depth\": 6,\n","            \"learning_rate\": 0.1,\n","            \"subsample\": 0.8,\n","            \"colsample_bytree\": 0.8,\n","            \"reg_lambda\": 1.0,\n","            \"tree_method\": \"hist\",\n","            \"eval_metric\": \"mlogloss\",\n","            \"test_accuracy\": acc,\n","            \"test_accuracy_percent\": acc_percent,\n","            \"train_time_sec\": round(train_time, 4),\n","            \"report_csv\": str(report_csv),\n","            \"confusion_matrix_csv\": str(cm_csv),\n","            \"model_path\": str(model_path)\n","        },\n","        f,\n","        indent=2\n","    )\n","\n","# Per-class correct and incorrect counts; spice mapping added when available\n","summary = []\n","for c in unique_classes:\n","    mask = (y_test == c)\n","    total = int(mask.sum())\n","    correct = int((y_pred[mask] == y_test[mask]).sum())\n","    incorrect = int(total - correct)\n","    cls_acc = round(100.0 * correct / total, 2) if total > 0 else 0.0\n","    summary.append({\n","        \"target\": int(c),\n","        \"spice\": spice_map.get(int(c), \"\") if spice_map else \"\",\n","        \"total_rows\": total,\n","        \"correct_rows\": correct,\n","        \"incorrect_rows\": incorrect,\n","        \"class_accuracy_percent\": cls_acc\n","    })\n","\n","per_class_df = pd.DataFrame(summary).sort_values(by=\"target\")\n","per_class_csv = OUT_DIR / \"xgb_resistance_per_class_outcomes.csv\"\n","per_class_df.to_csv(per_class_csv, index=False)\n","\n","# Console output\n","print(f\"XGBoost (resistance) accuracy: {acc_percent}%\")\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, digits=4))\n","\n","print(\"\\nConfusion matrix (rows=true, columns=pred):\")\n","print(cm_df.to_string())\n","\n","print(\"\\nPer-class outcomes:\")\n","print(per_class_df.to_string(index=False))\n","\n","print(\"\\nSaved files:\")\n","print(\" \", report_csv)\n","print(\" \", cm_csv)\n","print(\" \", model_path)\n","print(\" \", metrics_json)\n","print(\" \", per_class_csv)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L52pa10Wq6U7","executionInfo":{"status":"ok","timestamp":1759840589173,"user_tz":-660,"elapsed":33837,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"bd4f01a7-b50b-46fd-fc30-ca64f24f0a12"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost (resistance) accuracy: 40.82%\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0     0.5095    0.4542    0.4803     26800\n","           1     0.4111    0.4597    0.4341     26800\n","           2     0.3744    0.3750    0.3747     26800\n","           3     0.3476    0.3437    0.3456     26800\n","\n","    accuracy                         0.4082    107200\n","   macro avg     0.4107    0.4082    0.4087    107200\n","weighted avg     0.4107    0.4082    0.4087    107200\n","\n","\n","Confusion matrix (rows=true, columns=pred):\n","pred_label         pred_Anise (0)  pred_Chilli (1)  pred_Cinnamon (2)  pred_Nutmeg (3)\n","true_label                                                                            \n","true_Anise (0)              12173             3734               7431             3462\n","true_Chilli (1)              1621            12320               3621             9238\n","true_Cinnamon (2)            8283             3877              10050             4590\n","true_Nutmeg (3)              1814            10036               5739             9211\n","\n","Per-class outcomes:\n"," target    spice  total_rows  correct_rows  incorrect_rows  class_accuracy_percent\n","      0    Anise       26800         12173           14627                   45.42\n","      1   Chilli       26800         12320           14480                   45.97\n","      2 Cinnamon       26800         10050           16750                   37.50\n","      3   Nutmeg       26800          9211           17589                   34.37\n","\n","Saved files:\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/XGBoost/xgb_resistance_classification_report.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/XGBoost/xgb_resistance_confusion_matrix.csv\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/XGBoost/xgb_resistance_model.joblib\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/XGBoost/xgb_resistance_metrics.json\n","  /content/drive/My Drive/Final_Year_Project/Attempt_3_version_2/resistance/outputs/XGBoost/xgb_resistance_per_class_outcomes.csv\n"]}]}]}