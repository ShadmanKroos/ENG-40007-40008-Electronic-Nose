{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5HrQ0vxh4DMx+mLIE1MNa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhexhssdO1Kt","executionInfo":{"status":"ok","timestamp":1759900357498,"user_tz":-660,"elapsed":16212,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"1e8e8230-0bf2-4895-9dff-88d094b32144"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Drive mount logic kept minimal and predictable.\n","# Detect existing mount to avoid duplicate prompts; mount if absent.\n","\n","import os\n","from google.colab import drive\n","\n","if os.path.ismount('/content/drive'):\n","    print(\"OK: /content/drive is already mounted.\")\n","else:\n","    drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","source":["# Reviewer note: paths updated to Attempt_1_4_and_5_combined_version_2.\n","# Reviewer note: reduction keeps rel, log_slope_per_s, log_std, plus context means; IDs are preserved for downstream joins.\n","\n","import os\n","from pathlib import Path\n","import pandas as pd\n","import re\n","\n","# Project paths\n","TRAIN5 = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features/train/train_features.csv\"\n","TEST5  = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features/test/test_features.csv\"\n","\n","# Output directory for reduced features\n","OUT_REDUCED = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced\"\n","Path(OUT_REDUCED).mkdir(parents=True, exist_ok=True)\n","\n","ID_COLS = [\"group_id\",\"spice\",\"target\"]\n","CTX_COLS = [\"temp_mean\",\"rh_mean\",\"pressure_mean\"]\n","\n","def select_reduced_cols(df):\n","    # Reviewer note: ID columns excluded from feature list; context means retained explicitly.\n","    keep = []\n","    for c in df.columns:\n","        if c in ID_COLS:\n","            continue\n","        if c in CTX_COLS:\n","            keep.append(c)\n","            continue\n","        if c.endswith(\"_n\"):\n","            continue\n","        if re.search(r\"_rel$\", c):\n","            keep.append(c)\n","        elif c.endswith(\"_log_slope_per_s\"):\n","            keep.append(c)\n","        elif c.endswith(\"_log_std\"):\n","            keep.append(c)\n","    return keep\n","\n","def make_reduced(src_csv, dst_csv):\n","    # Reviewer note: preserve ID columns first; concatenate selected features for clarity and reproducibility.\n","    df = pd.read_csv(src_csv)\n","    feats = select_reduced_cols(df)\n","    reduced = pd.concat([df[ID_COLS], df[feats]], axis=1)\n","    reduced.to_csv(dst_csv, index=False)\n","    print(f\"[OK] Wrote reduced: {dst_csv}  | kept {len(feats)} feature columns\")\n","\n","make_reduced(TRAIN5, f\"{OUT_REDUCED}/train_reduced.csv\")\n","make_reduced(TEST5,  f\"{OUT_REDUCED}/test_reduced.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OeleRmKQPFmb","executionInfo":{"status":"ok","timestamp":1759900459225,"user_tz":-660,"elapsed":2304,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"9f0e5d15-95e5-4d42-c9ed-59ccf6998a08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[OK] Wrote reduced: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/train_reduced.csv  | kept 483 feature columns\n","[OK] Wrote reduced: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/test_reduced.csv  | kept 483 feature columns\n"]}]},{"cell_type":"code","source":["# Reviewer note: Random Forest on Reduced features; no cross-validation.\n","# Reviewer note: outputs are saved under Features_Reduced/outputs/RandomForest; accuracy printed as percentage.\n","# Reviewer note: per-cycle prediction table is printed; per-cycle summary removed as requested.\n","\n","import os, json, joblib\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    precision_recall_fscore_support, f1_score\n",")\n","\n","# Assumes OUT_REDUCED defined earlier, for example:\n","# OUT_REDUCED = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced\"\n","\n","# Output directory structure\n","OUT_ROOT = Path(OUT_REDUCED) / \"outputs\"\n","OUT_RF   = OUT_ROOT / \"RandomForest\"\n","OUT_RF.mkdir(parents=True, exist_ok=True)\n","\n","ID_COLS = [\"group_id\",\"spice\",\"target\"]\n","TARGET_COL = \"target\"\n","\n","# Load reduced train/test\n","train = pd.read_csv(f\"{OUT_REDUCED}/train_reduced.csv\")\n","test  = pd.read_csv(f\"{OUT_REDUCED}/test_reduced.csv\")\n","\n","X_train = train.drop(columns=ID_COLS, errors=\"ignore\")\n","y_train = train[TARGET_COL].astype(int).values\n","X_test  = test.drop(columns=ID_COLS, errors=\"ignore\")\n","y_test  = test[TARGET_COL].astype(int).values\n","\n","# Optional metadata for per-cycle predictions\n","meta_cols = [c for c in [\"group_id\",\"spice\"] if c in test.columns]\n","meta = test[meta_cols].copy() if meta_cols else pd.DataFrame(index=test.index)\n","\n","# Build and fit model\n","rf = RandomForestClassifier(\n","    n_estimators=800,\n","    max_depth=None,\n","    min_samples_split=2,\n","    min_samples_leaf=2,\n","    max_features=\"sqrt\",\n","    class_weight=\"balanced_subsample\",\n","    n_jobs=-1,\n","    random_state=42\n",")\n","rf.fit(X_train, y_train)\n","\n","# Persist model\n","joblib.dump(rf, OUT_RF / \"model.joblib\")\n","\n","# Predict on test\n","y_pred  = rf.predict(X_test)\n","labels  = np.unique(np.concatenate([y_train, y_test], axis=0))\n","\n","# Metrics\n","acc = float(accuracy_score(y_test, y_pred))\n","acc_pct = acc * 100.0\n","rep = classification_report(y_test, y_pred, labels=labels, digits=4)\n","p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, labels=labels, zero_division=0)\n","\n","metrics = {\n","    \"model\": \"random_forest\",\n","    \"accuracy\": acc,\n","    \"f1\": {\n","        \"macro\": float(f1_score(y_test, y_pred, average=\"macro\")),\n","        \"weighted\": float(f1_score(y_test, y_pred, average=\"weighted\"))\n","    },\n","    \"per_class\": {\n","        str(int(lbl)): {\"precision\": float(pi), \"recall\": float(ri), \"f1\": float(fi), \"support\": int(si)}\n","        for lbl, pi, ri, fi, si in zip(labels, p, r, f1, s)\n","    }\n","}\n","with open(OUT_RF / \"metrics.json\", \"w\") as f:\n","    json.dump(metrics, f, indent=2)\n","\n","# Save classification report\n","with open(OUT_RF / \"classification_report.txt\", \"w\") as f:\n","    f.write(rep)\n","\n","# Confusion matrix as CSV with clear headers\n","cm = confusion_matrix(y_test, y_pred, labels=labels)\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{int(i)}\" for i in labels],\n","    columns=[f\"pred_{int(i)}\" for i in labels]\n",")\n","cm_df.to_csv(OUT_RF / \"confusion_matrix.csv\", index=True)\n","\n","# Per-cycle predictions dataframe\n","preds = meta.copy()\n","preds[\"y_true\"] = y_test\n","preds[\"y_pred\"] = y_pred\n","preds.to_csv(OUT_RF / \"per_cycle_predictions.csv\", index=False)\n","\n","# Console summary\n","print(f\"[RandomForest] test accuracy: {acc_pct:.2f}%\")\n","print(\"\\n[RandomForest] classification report:\\n\", rep)\n","print(\"\\n[RandomForest] confusion matrix:\\n\", cm_df)\n","\n","# Print per-cycle prediction table to console (full table; no summary)\n","print(\"\\n[RandomForest] per_cycle_predictions (full table):\")\n","print(preds.to_string(index=False))\n","\n","print(\"\\n[RandomForest] outputs saved to:\", OUT_RF.resolve())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CKDyXUPlRJhO","executionInfo":{"status":"ok","timestamp":1759900909737,"user_tz":-660,"elapsed":3613,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"185964b9-2c30-4133-983b-761a4786e060"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[RandomForest] test accuracy: 45.00%\n","\n","[RandomForest] classification report:\n","               precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000         5\n","           1     0.0000    0.0000    0.0000         5\n","           2     0.5000    1.0000    0.6667         5\n","           3     1.0000    0.8000    0.8889         5\n","\n","    accuracy                         0.4500        20\n","   macro avg     0.3750    0.4500    0.3889        20\n","weighted avg     0.3750    0.4500    0.3889        20\n","\n","\n","[RandomForest] confusion matrix:\n","         pred_0  pred_1  pred_2  pred_3\n","true_0       0       5       0       0\n","true_1       1       0       4       0\n","true_2       0       0       5       0\n","true_3       0       0       1       4\n","\n","[RandomForest] per_cycle_predictions (full table):\n","        group_id    spice  y_true  y_pred\n","   Anise_cycle_1    Anise       0       1\n","   Anise_cycle_2    Anise       0       1\n","   Anise_cycle_3    Anise       0       1\n","   Anise_cycle_4    Anise       0       1\n","   Anise_cycle_5    Anise       0       1\n","  Chilli_cycle_1   Chilli       1       0\n","  Chilli_cycle_2   Chilli       1       2\n","  Chilli_cycle_3   Chilli       1       2\n","  Chilli_cycle_4   Chilli       1       2\n","  Chilli_cycle_5   Chilli       1       2\n","Cinnamon_cycle_1 Cinnamon       2       2\n","Cinnamon_cycle_2 Cinnamon       2       2\n","Cinnamon_cycle_3 Cinnamon       2       2\n","Cinnamon_cycle_4 Cinnamon       2       2\n","Cinnamon_cycle_5 Cinnamon       2       2\n","  Nutmeg_cycle_1   Nutmeg       3       3\n","  Nutmeg_cycle_2   Nutmeg       3       3\n","  Nutmeg_cycle_3   Nutmeg       3       3\n","  Nutmeg_cycle_4   Nutmeg       3       3\n","  Nutmeg_cycle_5   Nutmeg       3       2\n","\n","[RandomForest] outputs saved to: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/outputs/RandomForest\n"]}]},{"cell_type":"code","source":["# Reviewer note: Logistic Regression on Reduced features; no cross-validation.\n","# Reviewer note: outputs are saved under Features_Reduced/outputs/LogisticRegression; accuracy printed as percentage.\n","# Reviewer note: per-cycle prediction table is printed to the console (full table); no additional summary.\n","\n","import os, json, joblib\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    precision_recall_fscore_support, f1_score\n",")\n","\n","# Assumes OUT_REDUCED was defined previously, for example:\n","# OUT_REDUCED = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced\"\n","\n","# Output directory structure\n","OUT_ROOT = Path(OUT_REDUCED) / \"outputs\"\n","OUT_LR   = OUT_ROOT / \"LogisticRegression\"\n","OUT_LR.mkdir(parents=True, exist_ok=True)\n","\n","ID_COLS = [\"group_id\",\"spice\",\"target\"]\n","TARGET_COL = \"target\"\n","\n","# Load reduced train/test\n","train = pd.read_csv(f\"{OUT_REDUCED}/train_reduced.csv\")\n","test  = pd.read_csv(f\"{OUT_REDUCED}/test_reduced.csv\")\n","\n","X_train = train.drop(columns=ID_COLS, errors=\"ignore\")\n","y_train = train[TARGET_COL].astype(int).values\n","X_test  = test.drop(columns=ID_COLS, errors=\"ignore\")\n","y_test  = test[TARGET_COL].astype(int).values\n","\n","# Optional metadata for per-cycle predictions\n","meta_cols = [c for c in [\"group_id\",\"spice\"] if c in test.columns]\n","meta = test[meta_cols].copy() if meta_cols else pd.DataFrame(index=test.index)\n","\n","# Build and fit model\n","pipe = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", LogisticRegression(max_iter=5000, multi_class=\"auto\", random_state=42))\n","])\n","pipe.fit(X_train, y_train)\n","\n","# Persist model\n","joblib.dump(pipe, OUT_LR / \"model.joblib\")\n","\n","# Predict on test\n","y_pred  = pipe.predict(X_test)\n","labels  = np.unique(np.concatenate([y_train, y_test], axis=0))\n","\n","# Metrics\n","acc = float(accuracy_score(y_test, y_pred))\n","acc_pct = acc * 100.0\n","rep = classification_report(y_test, y_pred, labels=labels, digits=4)\n","p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, labels=labels, zero_division=0)\n","\n","metrics = {\n","    \"model\": \"logistic_regression\",\n","    \"accuracy\": acc,\n","    \"f1\": {\n","        \"macro\": float(f1_score(y_test, y_pred, average=\"macro\")),\n","        \"weighted\": float(f1_score(y_test, y_pred, average=\"weighted\"))\n","    },\n","    \"per_class\": {\n","        str(int(lbl)): {\"precision\": float(pi), \"recall\": float(ri), \"f1\": float(fi), \"support\": int(si)}\n","        for lbl, pi, ri, fi, si in zip(labels, p, r, f1, s)\n","    }\n","}\n","with open(OUT_LR / \"metrics.json\", \"w\") as f:\n","    json.dump(metrics, f, indent=2)\n","\n","# Save classification report\n","with open(OUT_LR / \"classification_report.txt\", \"w\") as f:\n","    f.write(rep)\n","\n","# Confusion matrix as CSV with clear headers\n","cm = confusion_matrix(y_test, y_pred, labels=labels)\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{int(i)}\" for i in labels],\n","    columns=[f\"pred_{int(i)}\" for i in labels]\n",")\n","cm_df.to_csv(OUT_LR / \"confusion_matrix.csv\", index=True)\n","\n","# Per-cycle predictions\n","preds = meta.copy()\n","preds[\"y_true\"] = y_test\n","preds[\"y_pred\"] = y_pred\n","preds.to_csv(OUT_LR / \"per_cycle_predictions.csv\", index=False)\n","\n","# Console summary\n","print(f\"[LogisticRegression] test accuracy: {acc_pct:.2f}%\")\n","print(\"\\n[LogisticRegression] classification report:\\n\", rep)\n","print(\"\\n[LogisticRegression] confusion matrix:\\n\", cm_df)\n","\n","# Print per-cycle prediction table to console (full table; no summary)\n","print(\"\\n[LogisticRegression] per_cycle_predictions (full table):\")\n","print(preds.to_string(index=False))\n","\n","print(\"\\n[LogisticRegression] outputs saved to:\", OUT_LR.resolve())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SGvDBVLhRVx4","executionInfo":{"status":"ok","timestamp":1759901079763,"user_tz":-660,"elapsed":1071,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"cf9f7392-e8ad-4ac5-a35a-9b778e22d444"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["[LogisticRegression] test accuracy: 70.00%\n","\n","[LogisticRegression] classification report:\n","               precision    recall  f1-score   support\n","\n","           0     1.0000    1.0000    1.0000         5\n","           1     0.0000    0.0000    0.0000         5\n","           2     0.4545    1.0000    0.6250         5\n","           3     1.0000    0.8000    0.8889         5\n","\n","    accuracy                         0.7000        20\n","   macro avg     0.6136    0.7000    0.6285        20\n","weighted avg     0.6136    0.7000    0.6285        20\n","\n","\n","[LogisticRegression] confusion matrix:\n","         pred_0  pred_1  pred_2  pred_3\n","true_0       5       0       0       0\n","true_1       0       0       5       0\n","true_2       0       0       5       0\n","true_3       0       0       1       4\n","\n","[LogisticRegression] per_cycle_predictions (full table):\n","        group_id    spice  y_true  y_pred\n","   Anise_cycle_1    Anise       0       0\n","   Anise_cycle_2    Anise       0       0\n","   Anise_cycle_3    Anise       0       0\n","   Anise_cycle_4    Anise       0       0\n","   Anise_cycle_5    Anise       0       0\n","  Chilli_cycle_1   Chilli       1       2\n","  Chilli_cycle_2   Chilli       1       2\n","  Chilli_cycle_3   Chilli       1       2\n","  Chilli_cycle_4   Chilli       1       2\n","  Chilli_cycle_5   Chilli       1       2\n","Cinnamon_cycle_1 Cinnamon       2       2\n","Cinnamon_cycle_2 Cinnamon       2       2\n","Cinnamon_cycle_3 Cinnamon       2       2\n","Cinnamon_cycle_4 Cinnamon       2       2\n","Cinnamon_cycle_5 Cinnamon       2       2\n","  Nutmeg_cycle_1   Nutmeg       3       2\n","  Nutmeg_cycle_2   Nutmeg       3       3\n","  Nutmeg_cycle_3   Nutmeg       3       3\n","  Nutmeg_cycle_4   Nutmeg       3       3\n","  Nutmeg_cycle_5   Nutmeg       3       3\n","\n","[LogisticRegression] outputs saved to: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/outputs/LogisticRegression\n"]}]},{"cell_type":"code","source":["# Reviewer note: SVM (RBF) on Reduced features; no cross-validation.\n","# Reviewer note: outputs are saved under Features_Reduced/outputs/SVM; accuracy printed as percentage.\n","# Reviewer note: per-cycle prediction table is printed to the console (full table); no additional summary.\n","\n","import os, json, joblib\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    precision_recall_fscore_support, f1_score\n",")\n","\n","# Base path for Reduced features\n","OUT_REDUCED = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced\"\n","TRAIN_RED = f\"{OUT_REDUCED}/train_reduced.csv\"\n","TEST_RED  = f\"{OUT_REDUCED}/test_reduced.csv\"\n","\n","# Output directory structure\n","OUT_ROOT = Path(OUT_REDUCED) / \"outputs\"\n","OUT_SVM  = OUT_ROOT / \"SVM\"\n","OUT_SVM.mkdir(parents=True, exist_ok=True)\n","\n","ID_COLS = [\"group_id\",\"spice\",\"target\"]\n","TARGET_COL = \"target\"\n","\n","# Load Reduced train/test\n","train = pd.read_csv(TRAIN_RED)\n","test  = pd.read_csv(TEST_RED)\n","\n","X_train = train.drop(columns=ID_COLS, errors=\"ignore\")\n","y_train = train[TARGET_COL].astype(int).values\n","X_test  = test.drop(columns=ID_COLS, errors=\"ignore\")\n","y_test  = test[TARGET_COL].astype(int).values\n","\n","# Optional metadata for per-cycle predictions\n","meta_cols = [c for c in [\"group_id\",\"spice\"] if c in test.columns]\n","meta = test[meta_cols].copy() if meta_cols else pd.DataFrame(index=test.index)\n","\n","# Build and fit model (no CV)\n","pipe = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=False, random_state=42))\n","])\n","pipe.fit(X_train, y_train)\n","\n","# Persist model\n","joblib.dump(pipe, OUT_SVM / \"model.joblib\")\n","\n","# Predict on test\n","y_pred  = pipe.predict(X_test)\n","labels  = np.unique(np.concatenate([y_train, y_test], axis=0))\n","\n","# Metrics\n","acc = float(accuracy_score(y_test, y_pred))\n","acc_pct = acc * 100.0\n","rep = classification_report(y_test, y_pred, labels=labels, digits=4)\n","p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, labels=labels, zero_division=0)\n","\n","metrics = {\n","    \"model\": \"svm_rbf\",\n","    \"accuracy\": acc,\n","    \"f1\": {\n","        \"macro\": float(f1_score(y_test, y_pred, average=\"macro\")),\n","        \"weighted\": float(f1_score(y_test, y_pred, average=\"weighted\"))\n","    },\n","    \"per_class\": {\n","        str(int(lbl)): {\"precision\": float(pi), \"recall\": float(ri), \"f1\": float(fi), \"support\": int(si)}\n","        for lbl, pi, ri, fi, si in zip(labels, p, r, f1, s)\n","    }\n","}\n","with open(OUT_SVM / \"metrics.json\", \"w\") as f:\n","    json.dump(metrics, f, indent=2)\n","\n","# Save classification report\n","with open(OUT_SVM / \"classification_report.txt\", \"w\") as f:\n","    f.write(rep)\n","\n","# Confusion matrix as CSV with clear headers\n","cm = confusion_matrix(y_test, y_pred, labels=labels)\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{int(i)}\" for i in labels],\n","    columns=[f\"pred_{int(i)}\" for i in labels]\n",")\n","cm_df.to_csv(OUT_SVM / \"confusion_matrix.csv\", index=True)\n","\n","# Per-cycle predictions\n","preds = meta.copy()\n","preds[\"y_true\"] = y_test\n","preds[\"y_pred\"] = y_pred\n","preds.to_csv(OUT_SVM / \"per_cycle_predictions.csv\", index=False)\n","\n","# Console summary\n","print(f\"[SVM_RBF_Reduced] test accuracy: {acc_pct:.2f}%\")\n","print(\"\\n[SVM_RBF_Reduced] classification report:\\n\", rep)\n","print(\"\\n[SVM_RBF_Reduced] confusion matrix:\\n\", cm_df)\n","\n","# Print per-cycle prediction table to console (full table; no summary)\n","print(\"\\n[SVM_RBF_Reduced] per_cycle_predictions (full table):\")\n","print(preds.to_string(index=False))\n","\n","print(\"\\n[SVM_RBF_Reduced] outputs saved to:\", OUT_SVM.resolve())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqx4R_w8R4w2","executionInfo":{"status":"ok","timestamp":1759901176932,"user_tz":-660,"elapsed":243,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"49204a68-a5f1-490b-e451-9f893fcb0323"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[SVM_RBF_Reduced] test accuracy: 40.00%\n","\n","[SVM_RBF_Reduced] classification report:\n","               precision    recall  f1-score   support\n","\n","           0     0.4545    1.0000    0.6250         5\n","           1     0.0000    0.0000    0.0000         5\n","           2     0.3333    0.6000    0.4286         5\n","           3     0.0000    0.0000    0.0000         5\n","\n","    accuracy                         0.4000        20\n","   macro avg     0.1970    0.4000    0.2634        20\n","weighted avg     0.1970    0.4000    0.2634        20\n","\n","\n","[SVM_RBF_Reduced] confusion matrix:\n","         pred_0  pred_1  pred_2  pred_3\n","true_0       5       0       0       0\n","true_1       3       0       2       0\n","true_2       2       0       3       0\n","true_3       1       0       4       0\n","\n","[SVM_RBF_Reduced] per_cycle_predictions (full table):\n","        group_id    spice  y_true  y_pred\n","   Anise_cycle_1    Anise       0       0\n","   Anise_cycle_2    Anise       0       0\n","   Anise_cycle_3    Anise       0       0\n","   Anise_cycle_4    Anise       0       0\n","   Anise_cycle_5    Anise       0       0\n","  Chilli_cycle_1   Chilli       1       0\n","  Chilli_cycle_2   Chilli       1       0\n","  Chilli_cycle_3   Chilli       1       0\n","  Chilli_cycle_4   Chilli       1       2\n","  Chilli_cycle_5   Chilli       1       2\n","Cinnamon_cycle_1 Cinnamon       2       0\n","Cinnamon_cycle_2 Cinnamon       2       0\n","Cinnamon_cycle_3 Cinnamon       2       2\n","Cinnamon_cycle_4 Cinnamon       2       2\n","Cinnamon_cycle_5 Cinnamon       2       2\n","  Nutmeg_cycle_1   Nutmeg       3       0\n","  Nutmeg_cycle_2   Nutmeg       3       2\n","  Nutmeg_cycle_3   Nutmeg       3       2\n","  Nutmeg_cycle_4   Nutmeg       3       2\n","  Nutmeg_cycle_5   Nutmeg       3       2\n","\n","[SVM_RBF_Reduced] outputs saved to: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/outputs/SVM\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# Reviewer note: XGBoost on Features_Reduced; no cross-validation.\n","# Reviewer note: all artifacts saved in a single folder Features_Reduced/outputs/XGBoost.\n","# Reviewer note: accuracy printed as percentage; per-cycle predictions printed to console (full table).\n","\n","import os, json, joblib\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","from xgboost import XGBClassifier\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    precision_recall_fscore_support, f1_score\n",")\n","\n","# Base path for Reduced features\n","OUT_REDUCED = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced\"\n","TRAIN_RED = f\"{OUT_REDUCED}/train_reduced.csv\"\n","TEST_RED  = f\"{OUT_REDUCED}/test_reduced.csv\"\n","\n","# Single output folder (no subdirectories)\n","OUT_XGB = Path(OUT_REDUCED) / \"outputs\" / \"XGBoost\"\n","OUT_XGB.mkdir(parents=True, exist_ok=True)\n","\n","ID_COLS = [\"group_id\",\"spice\",\"target\"]\n","TARGET_COL = \"target\"\n","\n","# Load Reduced train/test\n","train = pd.read_csv(TRAIN_RED)\n","test  = pd.read_csv(TEST_RED)\n","\n","X_train = train.drop(columns=ID_COLS, errors=\"ignore\")\n","y_train = train[TARGET_COL].astype(int).values\n","X_test  = test.drop(columns=ID_COLS, errors=\"ignore\")\n","y_test  = test[TARGET_COL].astype(int).values\n","\n","# Optional metadata for per-cycle predictions\n","meta_cols = [c for c in [\"group_id\",\"spice\"] if c in test.columns]\n","meta = test[meta_cols].copy() if meta_cols else pd.DataFrame(index=test.index)\n","\n","# Configure and fit model (no CV)\n","num_classes = int(np.unique(y_train).shape[0])\n","xgb = XGBClassifier(\n","    objective=\"multi:softmax\",\n","    num_class=num_classes,\n","    eval_metric=\"mlogloss\",\n","    n_estimators=400,\n","    learning_rate=0.1,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","xgb.fit(X_train, y_train)\n","\n","# Persist model into the same folder\n","joblib.dump(xgb, OUT_XGB / \"final_model_xgb_reduced.joblib\")\n","\n","# Predict on test\n","y_pred  = xgb.predict(X_test)\n","labels  = np.unique(np.concatenate([y_train, y_test], axis=0))\n","\n","# Metrics\n","acc = float(accuracy_score(y_test, y_pred))\n","acc_pct = acc * 100.0\n","rep = classification_report(y_test, y_pred, labels=labels, digits=4)\n","p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, labels=labels, zero_division=0)\n","\n","metrics = {\n","    \"model\": \"xgboost_multi_softmax_no_cv\",\n","    \"accuracy\": acc,\n","    \"f1\": {\n","        \"macro\": float(f1_score(y_test, y_pred, average=\"macro\")),\n","        \"weighted\": float(f1_score(y_test, y_pred, average=\"weighted\"))\n","    },\n","    \"per_class\": {\n","        str(int(lbl)): {\"precision\": float(pi), \"recall\": float(ri), \"f1\": float(fi), \"support\": int(si)}\n","        for lbl, pi, ri, fi, si in zip(labels, p, r, f1, s)\n","    }\n","}\n","\n","# Write all eval artifacts into the same folder\n","with open(OUT_XGB / \"metrics.json\", \"w\") as f:\n","    json.dump(metrics, f, indent=2)\n","\n","with open(OUT_XGB / \"classification_report.txt\", \"w\") as f:\n","    f.write(rep)\n","\n","cm = confusion_matrix(y_test, y_pred, labels=labels)\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{int(i)}\" for i in labels],\n","    columns=[f\"pred_{int(i)}\" for i in labels]\n",")\n","cm_df.to_csv(OUT_XGB / \"confusion_matrix.csv\", index=True)\n","\n","preds = meta.copy()\n","preds[\"y_true\"] = y_test\n","preds[\"y_pred\"] = y_pred\n","preds.to_csv(OUT_XGB / \"test_predictions.csv\", index=False)\n","\n","# Console summary\n","print(f\"[XGBoost_Reduced] test accuracy: {acc_pct:.2f}%\")\n","print(\"\\n[XGBoost_Reduced] classification report:\\n\", rep)\n","print(\"\\n[XGBoost_Reduced] confusion matrix:\\n\", cm_df)\n","\n","# Print per-cycle prediction table to console (full table; no summary)\n","print(\"\\n[XGBoost_Reduced] per_cycle_predictions (full table):\")\n","print(preds.to_string(index=False))\n","\n","print(\"\\n[XGBoost_Reduced] outputs saved to:\", OUT_XGB.resolve())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1r9-7U_j5Or","executionInfo":{"status":"ok","timestamp":1759905823256,"user_tz":-660,"elapsed":2087,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"f5e86ccc-8045-4c86-e5fd-fc69db5d0a6c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[XGBoost_Reduced] test accuracy: 10.00%\n","\n","[XGBoost_Reduced] classification report:\n","               precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000         5\n","           1     0.0000    0.0000    0.0000         5\n","           2     0.1818    0.4000    0.2500         5\n","           3     0.0000    0.0000    0.0000         5\n","\n","    accuracy                         0.1000        20\n","   macro avg     0.0455    0.1000    0.0625        20\n","weighted avg     0.0455    0.1000    0.0625        20\n","\n","\n","[XGBoost_Reduced] confusion matrix:\n","         pred_0  pred_1  pred_2  pred_3\n","true_0       0       5       0       0\n","true_1       1       0       4       0\n","true_2       0       0       2       3\n","true_3       0       0       5       0\n","\n","[XGBoost_Reduced] per_cycle_predictions (full table):\n","        group_id    spice  y_true  y_pred\n","   Anise_cycle_1    Anise       0       1\n","   Anise_cycle_2    Anise       0       1\n","   Anise_cycle_3    Anise       0       1\n","   Anise_cycle_4    Anise       0       1\n","   Anise_cycle_5    Anise       0       1\n","  Chilli_cycle_1   Chilli       1       2\n","  Chilli_cycle_2   Chilli       1       0\n","  Chilli_cycle_3   Chilli       1       2\n","  Chilli_cycle_4   Chilli       1       2\n","  Chilli_cycle_5   Chilli       1       2\n","Cinnamon_cycle_1 Cinnamon       2       2\n","Cinnamon_cycle_2 Cinnamon       2       2\n","Cinnamon_cycle_3 Cinnamon       2       3\n","Cinnamon_cycle_4 Cinnamon       2       3\n","Cinnamon_cycle_5 Cinnamon       2       3\n","  Nutmeg_cycle_1   Nutmeg       3       2\n","  Nutmeg_cycle_2   Nutmeg       3       2\n","  Nutmeg_cycle_3   Nutmeg       3       2\n","  Nutmeg_cycle_4   Nutmeg       3       2\n","  Nutmeg_cycle_5   Nutmeg       3       2\n","\n","[XGBoost_Reduced] outputs saved to: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/outputs/XGBoost\n"]}]},{"cell_type":"code","source":["# Reviewer note: KNN on Features_Reduced with CV+GridSearch; all artifacts saved in a single output folder.\n","# Reviewer note: per-cycle prediction table is printed to the console (full table); accuracy printed as percentage.\n","\n","import os, json, joblib\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.metrics import (\n","    accuracy_score, classification_report, confusion_matrix,\n","    precision_recall_fscore_support, f1_score\n",")\n","\n","# Base paths\n","OUT_REDUCED = \"/content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced\"\n","TRAIN_RED = f\"{OUT_REDUCED}/train_reduced.csv\"\n","TEST_RED  = f\"{OUT_REDUCED}/test_reduced.csv\"\n","\n","# Single output folder (no subdirectories)\n","OUT_KNN = Path(OUT_REDUCED) / \"outputs\" / \"KNN\"\n","OUT_KNN.mkdir(parents=True, exist_ok=True)\n","\n","# Load data\n","ID_COLS = [\"group_id\",\"spice\",\"target\"]\n","TARGET_COL = \"target\"\n","\n","tr = pd.read_csv(TRAIN_RED)\n","te = pd.read_csv(TEST_RED)\n","\n","X_tr = tr.drop(columns=ID_COLS, errors=\"ignore\").values\n","y_tr = tr[TARGET_COL].astype(int).values\n","\n","X_te = te.drop(columns=ID_COLS, errors=\"ignore\").values\n","y_te = te[TARGET_COL].astype(int).values\n","\n","meta_cols = [c for c in [\"group_id\",\"spice\"] if c in te.columns]\n","meta = te[meta_cols].copy() if meta_cols else pd.DataFrame(index=te.index)\n","\n","# Pipeline and CV grid\n","pipe_knn = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"clf\", KNeighborsClassifier())\n","])\n","\n","param_grid = {\n","    \"clf__n_neighbors\": [1, 3, 5, 7],\n","    \"clf__weights\": [\"uniform\", \"distance\"]\n","}\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","gs = GridSearchCV(\n","    estimator=pipe_knn,\n","    param_grid=param_grid,\n","    scoring=\"accuracy\",\n","    cv=cv,\n","    n_jobs=-1,\n","    refit=True,\n","    verbose=0\n",")\n","gs.fit(X_tr, y_tr)\n","\n","print(f\"[CV KNN-Reduced] best mean acc: {gs.best_score_:.4f}\")\n","print(\"[CV KNN-Reduced] best params:\", gs.best_params_)\n","\n","# Save CV summary into the single output folder\n","with open(OUT_KNN / \"cv_knn_reduced.json\",\"w\") as f:\n","    json.dump({\n","        \"best_score\": float(gs.best_score_),\n","        \"best_params\": gs.best_params_,\n","        \"n_features\": int(X_tr.shape[1]),\n","        \"n_samples\": int(X_tr.shape[0])\n","    }, f, indent=2)\n","\n","# Evaluate best estimator on held-out test\n","best_knn = gs.best_estimator_\n","y_pred = best_knn.predict(X_te)\n","\n","labels = np.unique(np.concatenate([y_tr, y_te], axis=0))\n","acc = float(accuracy_score(y_te, y_pred))\n","acc_pct = acc * 100.0\n","rep = classification_report(y_te, y_pred, labels=labels, digits=4)\n","p, r, f1, s = precision_recall_fscore_support(y_te, y_pred, labels=labels, zero_division=0)\n","\n","metrics = {\n","    \"model\": \"knn_cv_selected\",\n","    \"accuracy\": acc,\n","    \"f1\": {\n","        \"macro\": float(f1_score(y_te, y_pred, average=\"macro\")),\n","        \"weighted\": float(f1_score(y_te, y_pred, average=\"weighted\"))\n","    },\n","    \"per_class\": {\n","        str(int(lbl)): {\"precision\": float(pi), \"recall\": float(ri), \"f1\": float(fi), \"support\": int(si)}\n","        for lbl, pi, ri, fi, si in zip(labels, p, r, f1, s)\n","    },\n","    \"best_params\": gs.best_params_\n","}\n","\n","# Write all eval artifacts into the same folder\n","with open(OUT_KNN / \"metrics.json\",\"w\") as f:\n","    json.dump(metrics, f, indent=2)\n","\n","with open(OUT_KNN / \"classification_report.txt\",\"w\") as f:\n","    f.write(rep)\n","\n","cm = confusion_matrix(y_te, y_pred, labels=labels)\n","cm_df = pd.DataFrame(\n","    cm,\n","    index=[f\"true_{int(i)}\" for i in labels],\n","    columns=[f\"pred_{int(i)}\" for i in labels]\n",")\n","cm_df.to_csv(OUT_KNN / \"confusion_matrix.csv\", index=True)\n","\n","preds = meta.copy()\n","preds[\"y_true\"] = y_te\n","preds[\"y_pred\"] = y_pred\n","preds.to_csv(OUT_KNN / \"test_predictions.csv\", index=False)\n","\n","# Persist model into the same folder\n","joblib.dump(best_knn, OUT_KNN / \"final_model_knn_reduced.joblib\")\n","print(f\"[OK] Saved model to {OUT_KNN / 'final_model_knn_reduced.joblib'}\")\n","\n","# Console summary\n","print(f\"[TEST KNN-Reduced] accuracy: {acc_pct:.2f}%\")\n","print(\"\\n[TEST KNN-Reduced] classification report:\\n\", rep)\n","print(\"\\n[TEST KNN-Reduced] confusion matrix:\\n\", cm_df)\n","\n","# Print per-cycle prediction table to console (full table; no summary)\n","print(\"\\n[TEST KNN-Reduced] per_cycle_predictions (full table):\")\n","print(preds.to_string(index=False))\n","\n","print(\"\\n[TEST KNN-Reduced] outputs saved to:\", OUT_KNN.resolve())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6X4x7uzjO9d","executionInfo":{"status":"ok","timestamp":1759905649871,"user_tz":-660,"elapsed":456,"user":{"displayName":"Shadman Al Shams","userId":"05152644504485707243"}},"outputId":"af819c25-4261-40d2-9ca0-d2ab83a79dcc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[CV KNN-Reduced] best mean acc: 0.9500\n","[CV KNN-Reduced] best params: {'clf__n_neighbors': 5, 'clf__weights': 'uniform'}\n","[OK] Saved model to /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/outputs/KNN/final_model_knn_reduced.joblib\n","[TEST KNN-Reduced] accuracy: 70.00%\n","\n","[TEST KNN-Reduced] classification report:\n","               precision    recall  f1-score   support\n","\n","           0     0.6250    1.0000    0.7692         5\n","           1     1.0000    0.2000    0.3333         5\n","           2     0.5714    0.8000    0.6667         5\n","           3     1.0000    0.8000    0.8889         5\n","\n","    accuracy                         0.7000        20\n","   macro avg     0.7991    0.7000    0.6645        20\n","weighted avg     0.7991    0.7000    0.6645        20\n","\n","\n","[TEST KNN-Reduced] confusion matrix:\n","         pred_0  pred_1  pred_2  pred_3\n","true_0       5       0       0       0\n","true_1       1       1       3       0\n","true_2       1       0       4       0\n","true_3       1       0       0       4\n","\n","[TEST KNN-Reduced] per_cycle_predictions (full table):\n","        group_id    spice  y_true  y_pred\n","   Anise_cycle_1    Anise       0       0\n","   Anise_cycle_2    Anise       0       0\n","   Anise_cycle_3    Anise       0       0\n","   Anise_cycle_4    Anise       0       0\n","   Anise_cycle_5    Anise       0       0\n","  Chilli_cycle_1   Chilli       1       0\n","  Chilli_cycle_2   Chilli       1       1\n","  Chilli_cycle_3   Chilli       1       2\n","  Chilli_cycle_4   Chilli       1       2\n","  Chilli_cycle_5   Chilli       1       2\n","Cinnamon_cycle_1 Cinnamon       2       0\n","Cinnamon_cycle_2 Cinnamon       2       2\n","Cinnamon_cycle_3 Cinnamon       2       2\n","Cinnamon_cycle_4 Cinnamon       2       2\n","Cinnamon_cycle_5 Cinnamon       2       2\n","  Nutmeg_cycle_1   Nutmeg       3       0\n","  Nutmeg_cycle_2   Nutmeg       3       3\n","  Nutmeg_cycle_3   Nutmeg       3       3\n","  Nutmeg_cycle_4   Nutmeg       3       3\n","  Nutmeg_cycle_5   Nutmeg       3       3\n","\n","[TEST KNN-Reduced] outputs saved to: /content/drive/My Drive/Final_Year_Project/Attempt_1_4_and_5_combined_version_2/Features_Reduced/outputs/KNN\n"]}]}]}